seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
# calculate number of widths in each iteration
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
# extract ALL the models with < 5% error with 5-6 widths
juv_min_models <- filter(cse_by_nwidths, n_widths %in% c(5,6) & prop_error < 0.05)
nrow(filter(juv_min_models))
juv_best_width_combos <- filter(width_presence, iteration %in% juv_min_models$iteration)
# load all the ~500k width combos that made it through the first round of tests
juv_candidate_model_widths <- read_csv('data_minimized/L3/0120_candidate-adult-models_juv-data.csv')
`%ni%` <- Negate(`%in%`)
juvie_data_w_repeats <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(rep_class=='juvenile')
juv_candidate_model_widths$Animal_ID <- rep(juvie_data_w_repeats$Animal_ID, each=nrow(juv_best_width_combos))
juv_candidate_model_widths <- juv_candidate_model_widths %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
full_model_data <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
# assign model numbers
juv_candidate_model_widths$model <- rep(juv_min_models$iteration, length(unique(full_model_data$Animal_ID)))
# assign rep class
juv_accepted_widths <- filter(juv_candidate_model_widths, model %in% juv_accepted_models$model) %>% mutate(
rep_class = 'juvenile'
)
# rename columns to match adult dataset
colnames(juv_accepted_widths)[3:19] <- paste0('V', 4:20)
############## juvenile stuff ################
bmesh_run_1 <- read_csv("data_minimized/L2/0119_juv_75k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0119_juv_end.csv")
no_width_data <- read_csv('data_minimized/L2/0119_juv_no-widths.csv')
segment_vols <-  bind_rows(no_width_data, bmesh_run_1, bmesh_run_2)
segment_vols$iteration <- segment_vols$iteration+1
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
# calculate number of widths in each iteration
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
# extract ALL the models with < 5% error with 5-6 widths
juv_min_models <- filter(cse_by_nwidths, n_widths %in% c(5,6) & prop_error < 0.05)
nrow(filter(juv_min_models))
juv_best_width_combos <- filter(width_presence, iteration %in% juv_min_models$iteration)
##### make the subset dataframe to feed into blender
`%ni%` <- Negate(`%in%`)
width_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
juv_morphs <- filter(width_data, rep_class=='juvenile') %>% select(-Image)
best_models <- data.frame()
candidate_models <- read_csv('data_minimized/L4/0121_all-juvie-candidate-models.csv')
juvie_data_w_repeats <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(rep_class=='juvenile')
candidate_models$Animal_ID <- rep(juvie_data_w_repeats$Animal_ID, each=nrow(juv_best_width_combos))
candidate_models <- candidate_models %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
full_model_data <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
colnames(full_model_data)[1:18] <- 1:18
full_model_data <- pivot_longer(full_model_data, cols = `1`:`18`, names_to = 'segment')
# calculate total body volume
full_model_data <- full_model_data %>% group_by(Animal_ID) %>% mutate(body_volume = sum(value)) %>% mutate(
segment = as.numeric(segment)
) %>% rename(
true_segment_volume = 'value',
true_body_volume = 'body_volume'
)
model_and_nwidths_df <- juv_best_width_combos %>% slice(rep(row_number(), 41)) %>% # number of measurements
mutate(Animal_ID = rep(juv_morphs$Animal_ID, each=nrow(juv_best_width_combos))) %>% rename(
model = 'iteration')# add the IDs of the models
# just group by iteration and number of widths
candidate_models <- bind_cols(candidate_models, select(model_and_nwidths_df, c(model, n_widths)))
colnames(candidate_models)[1:18] <- 1:18
candidate_models <- pivot_longer(candidate_models, cols = `1`:`18`, names_to = 'segment') %>% mutate(segment=as.numeric(segment)) %>% rename(
candidate_segment_vol = 'value'
)
candidate_models <-  left_join(candidate_models, full_model_data, by = c('Animal_ID', 'segment'))
candidate_models <- candidate_models %>% group_by(Animal_ID, model) %>%
mutate(segment_error = candidate_segment_vol - true_segment_volume,
prop_seg_error = abs(segment_error/true_body_volume)) # prop is absolute
# add up error
juv_cum_seg_error <- candidate_models %>%
group_by(Animal_ID, model) %>%
summarise(total_prop_error=sum(prop_seg_error))
juv_accepted_models <- juv_cum_seg_error %>% group_by(model) %>% filter(quantile(total_prop_error, 0.95) < 0.05)
juv_accepted_models$rep_class <- 'juvenile'
View(juv_accepted_models)
############## juvenile stuff ################
bmesh_run_1 <- read_csv("data_minimized/L2/0119_juv_75k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0119_juv_end.csv")
no_width_data <- read_csv('data_minimized/L2/0119_juv_no-widths.csv')
segment_vols <-  bind_rows(no_width_data, bmesh_run_1, bmesh_run_2)
segment_vols$iteration <- segment_vols$iteration+1
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
# calculate number of widths in each iteration
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
# extract ALL the models with < 5% error with 5-6 widths
juv_min_models <- filter(cse_by_nwidths, n_widths %in% c(5,6) & prop_error < 0.05)
nrow(filter(juv_min_models))
juv_best_width_combos <- filter(width_presence, iteration %in% juv_min_models$iteration)
# load all the ~500k width combos that made it through the first round of tests
juv_candidate_model_widths <- read_csv('data_minimized/L3/0120_candidate-adult-models_juv-data.csv')
`%ni%` <- Negate(`%in%`)
juvie_data_w_repeats <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(rep_class=='juvenile')
juv_candidate_model_widths$Animal_ID <- rep(juvie_data_w_repeats$Animal_ID, each=nrow(juv_best_width_combos))
juv_candidate_model_widths <- juv_candidate_model_widths %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
full_model_data <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
# assign model numbers
juv_candidate_model_widths$model <- rep(juv_min_models$iteration, length(unique(full_model_data$Animal_ID)))
# assign rep class
juv_accepted_widths <- filter(juv_candidate_model_widths, model %in% juv_accepted_models$model) %>% mutate(
rep_class = 'juvenile'
)
juv_accepted_models <- read_csv('data_minimized/L5/20220426_optimal-juv-models.csv')
# assign rep class
juv_accepted_widths <- filter(juv_candidate_model_widths, model %in% juv_accepted_models$model) %>% mutate(
rep_class = 'juvenile'
)
View(juv_accepted_widths)
# rename columns to match adult dataset
colnames(juv_accepted_widths)[3:19] <- paste0('V', 4:20)
bmesh_run_1 <- read_csv("data_minimized/L2/0308_adult_0to30k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0308_adult_30to60k.csv")
bmesh_run_3 <- read_csv("data_minimized/L2/0308_adult_60to90k.csv")
bmesh_run_4 <- read_csv("data_minimized/L2/0308_adult_90ktoend.csv")
segment_vols= rbind(bmesh_run_1, bmesh_run_2, bmesh_run_3, bmesh_run_4)
segment_vols$iteration=1:nrow(segment_vols)
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
# convert to proportional error
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
cse_by_nwidths$rep_class <- 'adult'
adult_cse <- cse_by_nwidths
# extract ALL the models with < 5% error with 2-5 widths
adult_min_models <- filter(adult_cse, n_widths %in% c(2,3,4,5) & prop_error < 0.05)
#nrow(filter(juv_cse, prop_error < 0.05))
adult_best_width_combos <- filter(width_presence, iteration %in% adult_min_models$iteration)
adult_accepted_models2 <- read_csv('data_minimized/L5/20220426_optimal-adult-models.csv')
head(adult_accepted_models2)
adult_best_model_widths <- read.csv('data_minimized/L3/0309_adult_minmodels.csv')
# assign the model # to the actual width values
adult_best_model_widths$model <- rep(adult_best_width_combos$iteration, length(unique(adult_best_model_widths$Animal_ID)))
# filter the widths that were 'good enough' for adults
adult_accepted_widths <- filter(adult_best_model_widths, model %in% adult_accepted_models2$model) %>% rename (
TL = 'WL'
)
View(adult_accepted_widths)
# combine
both_acc_widths <- bind_rows(adult_accepted_widths, juv_accepted_widths)
# these are just the width measurement combinations used for indexing and animal IDs
adult_best_model_widths <- read.csv('data_minimized/L3/0309_adult_minmodels.csv')
true_vols <- read_csv("data_minimized/L2/all_adults_full_models_old-version.csv")
true_vols$Animal_ID <- unique(adult_best_model_widths$Animal_ID)
colnames(true_vols)[1:18] <- 1:18
true_vols <- pivot_longer(true_vols, cols = `1`:`18`, names_to = 'segment')
# calculate total body volume
true_vols <- true_vols %>% group_by(Animal_ID) %>% mutate(body_volume = sum(value))
# rename columns for clarity
true_vols <- true_vols %>% rename(
true_segment_volume = 'value',
true_body_volume = 'body_volume'
)  %>% mutate(
rep_class = 'adult',
segment = as.numeric(segment)
)
##### load JUVENILE stuff next  ###########
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
##### load JUVENILE stuff next  ###########
`%ni%` <- Negate(`%in%`)
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
full_model_data <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
juvie_data_w_repeats <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(rep_class=='juvenile')
full_model_data <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
##### load JUVENILE stuff next  ###########
`%ni%` <- Negate(`%in%`)
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
all_juvie_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1') & rep_class=='juvenile') # remove the 2 repeats
juvie_data_w_repeats <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(rep_class=='juvenile')
juv_full_model_vols <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
View(juv_full_model_vols)
colnames(juv_full_model_vols)[1:18] <- 1:18
juv_full_model_vols <- pivot_longer(juv_full_model_vols, cols = `1`:`18`, names_to = 'segment')
# calculate total body volume
juv_full_model_vols <- juv_full_model_vols %>% group_by(Animal_ID) %>% mutate(body_volume = sum(value)) %>% mutate(
segment = as.numeric(segment),
rep_class = 'juvenile'
) %>% rename(
true_segment_volume = 'value',
true_body_volume = 'body_volume'
)
all_full_models <- bind_rows(true_vols, juv_full_model_vols)
full_elliptical_seg_vols <- read_csv('data_minimized/L2/20220426_full-elliptical-model-seg-volumes.csv')
colnames(full_elliptical_seg_vols)[1:18] <- 1:18
full_elliptical_seg_vols <- read_csv('data_minimized/L2/20220426_full-elliptical-model-seg-volumes.csv')
colnames(full_elliptical_seg_vols)[1:18] <- 1:18
full_elliptical_seg_vols <- read_csv('data_minimized/L2/20220426_full-elliptical-model-seg-volumes.csv')
colnames(full_elliptical_seg_vols)[1:18] <- 1:18
full_elliptical_seg_vols <- full_elliptical_seg_vols %>% mutate(Animal_ID = ifelse(Animal_ID==lead(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID)) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
full_elliptical_seg_vols <- pivot_longer(full_elliptical_seg_vols, cols = `1`:`18`, names_to = 'segment') %>% mutate(
segment=as.numeric(segment)) %>% rename(
candidate_segment_vol = 'value'
)
full_elliptical_seg_vols <- left_join(full_elliptical_seg_vols, all_full_models, by = c('Animal_ID', 'segment', 'rep_class'))
full_elliptical_seg_vols <- full_elliptical_seg_vols %>% mutate(
segment_error = candidate_segment_vol - true_segment_volume,
prop_seg_error = abs(segment_error/true_body_volume)
) # prop is absolute
# add up error
full_elliptical_seg_vols_cse <- full_elliptical_seg_vols %>%
group_by(Animal_ID, rep_class) %>%
summarise(total_prop_error=sum(prop_seg_error)) %>% mutate(
model= 'full'
)
elliptical_seg_vols <- read_csv('data_minimized/L2/20220426_elliptical-model-seg-volumes.csv')
colnames(elliptical_seg_vols)[1:18] <- 1:18
elliptical_seg_vols <- pivot_longer(elliptical_seg_vols, cols = `1`:`18`, names_to = 'segment') %>% mutate(
segment=as.numeric(segment)) %>% rename(
candidate_segment_vol = 'value'
)
elliptical_seg_vols <- left_join(elliptical_seg_vols, all_full_models, by = c('Animal_ID', 'segment', 'rep_class'))
elliptical_seg_vols <- elliptical_seg_vols %>% mutate(
segment_error = candidate_segment_vol - true_segment_volume,
prop_seg_error = abs(segment_error/true_body_volume)
) # prop is absolute
# add up error
elliptical_cse <- elliptical_seg_vols %>%
group_by(Animal_ID, model, rep_class) %>%
summarise(total_prop_error=sum(prop_seg_error))
ggplot(elliptical_cse, aes(Animal_ID, total_prop_error, color=rep_class)) + geom_boxplot()
ggplot(elliptical_cse, aes(rep_class, total_prop_error, color=rep_class)) + geom_boxplot()
elliptical_cse <- read_csv('data_minimized/L2/20220426_optimal-elliptical-models.csv')
elliptical_cse <- read_csv('data_minimized/L3/20220426_optimal-elliptical-models.csv')
elliptical_cse <- elliptical_cse %>% mutate(method = 'elliptical')
elliptical_cse$model <- as.character('minimal')
full_elliptical_cse <- read_csv('data_minimized/L3/20220426_full-elliptical-models.csv')
full_elliptical_cse <- full_elliptical_cse %>% mutate(
method = 'elliptical')
full_elliptical_cse$model <- as.character('full')
accepted_adult_models <- read_csv('data_minimized/L5/20220426_optimal-adult-models.csv')
accepted_adult_models <- accepted_adult_models %>% mutate(
method = '3DM')
accepted_adult_models$model <- as.character('minimal')
accepted_juv_models <- read_csv('data_minimized/L5/20220426_optimal-juv-models.csv')
accepted_juv_models <-  accepted_juv_models %>%
select(-c('cs_error', 'perfect_vol')) %>%
rename(total_prop_error = 'prop_error') %>%
mutate(
method = '3DM')
accepted_juv_models$model <- as.character('minimal')
all_methods_cse <- bind_rows(full_elliptical_cse, elliptical_cse, accepted_adult_models, accepted_juv_models)#, fake_no_error_df)
ggplot(all_methods_cse, aes(rep_class, total_prop_error, color = method, linetype = model)) + geom_boxplot() + geom_hline(yintercept=0.05) + coord_cartesian(ylim=c(0,0.25)) + theme_bw()
all_methods_cse <- all_methods_cse %>%
mutate(model = stringr::str_to_title(model),
method = ifelse(method=='elliptical', 'Elliptical', method)) %>%
mutate(`model and method` = paste0(model, ',\n', method))
# filter outliers
smry_df <- all_methods_cse %>% group_by(Animal_ID, `model and method`, rep_class) %>% summarise(mean_error_perc = mean(total_prop_error)*100) %>% mutate(rep_class = stringr::str_to_title(rep_class)) %>% filter(mean_error_perc < 15)
ggplot(smry_df, aes(`model and method`, mean_error_perc, color = `model and method`)) +
geom_violin() +
#geom_boxplot() +
geom_jitter(height = 0) +
geom_hline(yintercept=5, linetype='dashed') +
theme_bw() +
facet_wrap(vars(rep_class)) +
ylab('Volume Error (% Total Volume)') +
xlab('Model and Method') +
theme(legend.position = 'none',
#legend.background = element_blank(),
#legend.box.background = element_rect(),
axis.title.x = element_text(size=16, margin=margin(t=8)),
axis.title.y = element_text(size=16, margin=margin(r=8)),
axis.text.y = element_text(size = 10),
axis.text.x = element_text(size=12, margin=margin(t=8)),
strip.text = element_text(size=12)) +
#coord_cartesian(ylim=c(0,15)) +
scale_color_viridis_d(option = 'C', end=0.7)
library(tidyverse)
# lets only address volume betweeen 20-85% TL
vols <- read_csv('data_minimized/L2/20220511_skinny-fat-whale-comp_vol.csv') %>%
select(-c(`0`, `2`, `4`, `6`, `34`))
# transform data steps
vols <- pivot_longer(vols, cols = `8`:`32`, names_to = 'segment')
vols$segment <- (as.numeric(vols$segment)+2)/2
# calculate total volume
vols <-  vols %>% group_by(Animal_ID, rep_class) %>% mutate(total_vol = sum(value))
vols <- vols %>%
mutate(Animal_ID = ifelse(Animal_ID=='TL0026', 'TL0026_enlarged', Animal_ID)) %>%
mutate(Animal_ID = factor(Animal_ID))  #%>% filter(error_method=='no_error')
# assign factor levels correctly...
levels(vols$Animal_ID) <- c('Poor BC', 'High BC')
# standardize to TL; TL = 13.830
# normalize BCI to mean value
vol_smry <- vols %>% group_by(Animal_ID) %>% summarise(seg_sum = sum(value)) %>%
mutate(TL = 13.830) %>%
mutate(BCI = 100*seg_sum/(0.65*TL)^3) %>%
ungroup() %>%
mutate(normalized_BCI = BCI/mean(BCI))
# lets only address SA betweeen 20-85% TL
SA <- read_csv('data_minimized/L2/20220511_skinny-fat-whale-comp_SA.csv') %>% select(-c(`1`, `3`, `5`, `7`, `35`))
SA <- pivot_longer(SA, cols = `9`:`33`, names_to = 'segment')
SA$segment <- (as.numeric(SA$segment)+1)/2
# calculate total volume
SA <-  SA %>% group_by(Animal_ID, rep_class) %>% mutate(total_vol = sum(value))
SA <- SA %>%
mutate(Animal_ID = ifelse(Animal_ID=='TL0026', 'TL0026_enlarged', Animal_ID)) %>%
mutate(Animal_ID = factor(Animal_ID))  #%>% filter(error_method=='no_error')
# assign factor levels correctly...
levels(SA$Animal_ID) <- c('Poor BC', 'High BC')
# standardize to TL; TL = 13.830
# normalize BCI to mean value
SA_smry <- SA %>% group_by(Animal_ID) %>% summarise(seg_sum = sum(value)) %>%
mutate(TL = 13.830) %>%
mutate(BCI = 100*seg_sum/(0.65*TL)^3) %>%
ungroup() %>%
mutate(normalized_BCI = BCI/mean(BCI))
bierlich_vol_cv2 <- vol_smry %>%
select(c(Animal_ID, normalized_BCI)) %>%
#mutate(seg_sum_std = seg_sum/mean(seg_sum)) %>%
mutate(std_dev = (0.062*normalized_BCI)) %>%
mutate(method='Volume Metric \n')
bierlich_sa_cv2 <- SA_smry %>%
select(c(Animal_ID, normalized_BCI)) %>%
#mutate(seg_sum_std = seg_sum/mean(seg_sum)) %>%
mutate(std_dev = (0.0131*normalized_BCI)) %>%
mutate(method='Surface Area Metric \n')
# combined the datasets again
bier_vol_sa <- bind_rows(bierlich_vol_cv2, bierlich_sa_cv2)
plot_df <- bier_vol_sa %>% mutate(ymin = normalized_BCI - std_dev,
ymax = normalized_BCI + std_dev,
group_var = factor(paste(method, Animal_ID)))
plot_df$group_var <- factor(plot_df$group_var, levels = c('Surface Area Metric \n Poor BC',
'Surface Area Metric \n High BC',
'Volume Metric \n Poor BC',
'Volume Metric \n High BC'))
library(scales)
show_col(viridis_pal(alpha=1, option = 'E')(10))
ggplot(plot_df, aes(group_var, normalized_BCI, fill=method)) +
geom_bar(stat='identity', width = 0.75, position = position_dodge(width = 1)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.2) +
theme(legend.position = 'none',
axis.title.x = element_blank(),
axis.title.y = element_text(size=12, margin=margin(r=8)),
axis.text.x = element_text(size=10, margin=margin(t=8)),
axis.text.y = element_text(size=12, margin=margin(r=0))) +
scale_fill_manual(values = my_cols) +
ylab('Normalized BCI')
my_cols <- viridis_pal(alpha=1, option = 'C')(10)[c(6,7)]
ggplot(plot_df, aes(group_var, normalized_BCI, fill=method)) +
geom_bar(stat='identity', width = 0.75, position = position_dodge(width = 1)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.2) +
theme(legend.position = 'none',
axis.title.x = element_blank(),
axis.title.y = element_text(size=12, margin=margin(r=8)),
axis.text.x = element_text(size=10, margin=margin(t=8)),
axis.text.y = element_text(size=12, margin=margin(r=0))) +
scale_fill_manual(values = my_cols) +
ylab('Normalized BCI')
tiff("figs/Fig-S1.tiff", units="in", width=6.5, height=4.5, res=300)
ggplot(plot_df, aes(group_var, normalized_BCI, fill=method)) +
geom_bar(stat='identity', width = 0.75, position = position_dodge(width = 1)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.2) +
theme(legend.position = 'none',
axis.title.x = element_blank(),
axis.title.y = element_text(size=12, margin=margin(r=8)),
axis.text.x = element_text(size=10, margin=margin(t=8)),
axis.text.y = element_text(size=12, margin=margin(r=0))) +
scale_fill_manual(values = my_cols) +
ylab('Normalized BCI')
dev.off()
Dorso_lateral_data <- read_table("data_minimized/L0/Dorso.lateral.data.2017.2020.2021.txt")
colnames(Dorso_lateral_data) <- c('ID', 'rep_class', 'location', paste('w', as.character(seq(0.05, 0.95, 0.05)), sep = ''), paste('h', as.character(seq(0.05, 0.95, 0.05)), sep = ''), 'drslname', 'latname')
# assumed all individuals were 12 m long
# remove quotation marks
# remove outlier
data_in_analysis <- Dorso_lateral_data %>% mutate(across(w0.05:h0.95, .fns = ~ .x*12)) %>%
mutate(rep_class = gsub('"', '', rep_class),
ID = gsub('"', '', ID),
location = gsub('"', '', location)) %>%
filter(rep_class %in% c('Adult', 'Juvenile') & ID != '2017.06.15.60.01b') %>%
mutate(TL=12)
# get dates
data_in_analysis <- data_in_analysis %>% mutate(
date = anytime::anydate(substr(ID, 1, 10)),
month = lubridate::month(date),
year = lubridate::year(date),
dataset = 'Australia'
)
table_df <- data_in_analysis %>% select(c('ID', 'dataset', 'location', 'rep_class', 'date')) %>% rename(Animal_ID = "ID")
library(flextable)
# read in NY data
NY_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv')
`%ni%` <- Negate(`%in%`)
# extract dates from Image column based on formattting
NY_data <- NY_data %>% mutate(
date = case_when(startsWith(Image, 'file') ~ substr(Image, 39, 46),
startsWith(Image, 'UAV_L0') ~ substr(Image, 13, 20),
startsWith(Image, 'final_formeas_file____Volumes') ~ substr(Image, 65, 72),
startsWith(Image, 'final_formeas_file____Users_EIH_Desktop') ~ '2021-10-07',
startsWith(Image, 'final_formeas_file____Users_EIH_Documents') ~ '2021-10-15')) %>%
mutate(
date = anytime::anydate(date),
dataset = 'New York',
location = '--',
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID),
rep_class = stringr::str_to_title(rep_class)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
NY_table_df <-  NY_data %>% select(c('Animal_ID', 'dataset', 'location', 'rep_class', 'date'))
table_df <- bind_rows(table_df, NY_table_df)
ft1 <- flextable(data=table_df) %>% set_header_labels(dataset = 'Dataset', location = 'Location', rep_class = 'Repr. Class', Animal_ID = 'Animal ID', date = 'Date') %>%
#theme_booktabs() %>%
align(j=1, align = 'left', part = 'body') %>%
align(j=2, align = 'center', part = 'body') %>%
align(j=3, align = 'center', part = 'body') %>%
align(j=4, align = 'center', part = 'body')
autofit(ft1)
save_as_docx(autofit(ft1), path = 'figs/table-S1.docx')
