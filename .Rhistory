# normalize BCI to mean value
vol_smry <- vols %>% group_by(Animal_ID) %>% summarise(seg_sum = sum(value)) %>%
mutate(TL = 13.830) %>%
mutate(BCI = 100*seg_sum/(0.65*TL)^3) %>%
ungroup() %>%
mutate(normalized_BCI = BCI/mean(BCI))
#### SA stuff
# lets only address SA betweeen 20-85% TL
SA <- read_csv('data_minimized/L2/20220511_skinny-fat-whale-comp_SA.csv') %>% select(-c(`1`, `3`, `5`, `7`, `35`))
SA <- pivot_longer(SA, cols = `9`:`33`, names_to = 'segment')
SA$segment <- (as.numeric(SA$segment)+1)/2
# calculate total volume
SA <-  SA %>% group_by(Animal_ID, rep_class) %>% mutate(total_vol = sum(value))
# we only want the fattest whale
#vols <- filter(vols, ID %in% c('TL0032'))
# load the data for the skinny whale (TL0026), when the whale has been transformed to the same length as TL0032
#vols2 <- read_csv('data/L2/0117_vol_error_comp2.csv') %>% select(-c(`0`, `2`, `4`, `6`, `34`))
# transform the data
#vols2 <- pivot_longer(vols2, cols = `8`:`32`, names_to = 'segment')
#vols2$segment <- (as.numeric(vols2$segment)+2)/2
#vols2 <-  vols2 %>% group_by(ID, rep_class, error_method) %>% mutate(total_vol = sum(value))
# make a new name for the 'skinny' whale stretched to the same length as TL0032
#vols2$ID <- 'TL0026_enlarged'
SA <- SA %>%
mutate(Animal_ID = ifelse(Animal_ID=='TL0026', 'TL0026_enlarged', Animal_ID)) %>%
mutate(Animal_ID = factor(Animal_ID))  #%>% filter(error_method=='no_error')
# assign factor levels correctly...
levels(SA$Animal_ID) <- c('Poor BC', 'High BC')
# standardize to TL; TL = 13.830
# normalize BCI to mean value
SA_smry <- SA %>% group_by(Animal_ID) %>% summarise(seg_sum = sum(value)) %>%
mutate(TL = 13.830) %>%
mutate(BCI = 100*seg_sum/(0.65*TL)^3) %>%
ungroup() %>%
mutate(normalized_BCI = BCI/mean(BCI))
###### calculate sds... percents can be done at any step of the way
bierlich_vol_cv2 <- vol_smry %>%
select(c(Animal_ID, normalized_BCI)) %>%
#mutate(seg_sum_std = seg_sum/mean(seg_sum)) %>%
mutate(std_dev = (0.062*normalized_BCI)) %>%
mutate(method='Volume Metric \n')
bierlich_sa_cv2 <- SA_smry %>%
select(c(Animal_ID, normalized_BCI)) %>%
#mutate(seg_sum_std = seg_sum/mean(seg_sum)) %>%
mutate(std_dev = (0.0131*normalized_BCI)) %>%
mutate(method='Surface Area Metric \n')
# combined the datasets again
bier_vol_sa <- bind_rows(bierlich_vol_cv2, bierlich_sa_cv2)
# make a plot
plot_df <- bier_vol_sa %>% mutate(ymin = normalized_BCI - std_dev,
ymax = normalized_BCI + std_dev,
group_var = factor(paste(method, Animal_ID)))
plot_df$group_var <- factor(plot_df$group_var, levels = c('Surface Area Metric \n Poor BC',
'Surface Area Metric \n High BC',
'Volume Metric \n Poor BC',
'Volume Metric \n High BC'))
library(scales)
my_cols <- viridis_pal(alpha=1, option = 'C')(10)[c(6,7)]
tiff("figs/fig-S1.tiff", units="in", width=6.5, height=4.5, res=300)
ggplot(plot_df, aes(group_var, normalized_BCI, fill=method)) +
geom_bar(stat='identity', width = 0.75, position = position_dodge(width = 1)) +
geom_point() +
theme_bw() +
geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.2) +
theme(legend.position = 'none',
axis.title.x = element_blank(),
axis.title.y = element_text(size=12, margin=margin(r=8)),
axis.text.x = element_text(size=10, margin=margin(t=8)),
axis.text.y = element_text(size=12, margin=margin(r=0))) +
scale_fill_manual(values = my_cols) +
ylab('Normalized BCI')
dev.off()
########### this file generates figure 4 ################
library(tidyverse)
bmesh_run_1 <- read_csv("data_minimized/L2/0308_adult_0to30k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0308_adult_30to60k.csv")
bmesh_run_3 <- read_csv("data_minimized/L2/0308_adult_60to90k.csv")
bmesh_run_4 <- read_csv("data_minimized/L2/0308_adult_90ktoend.csv")
segment_vols= rbind(bmesh_run_1, bmesh_run_2, bmesh_run_3, bmesh_run_4)
segment_vols$iteration=1:nrow(segment_vols)
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
# make indices of model combinations
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
# convert to proportional error
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
cse_by_nwidths$rep_class <- 'Adult'
adult_cse <- cse_by_nwidths
########### JUVENILE DATA #########################
bmesh_run_1 <- read_csv("data_minimized/L2/0119_juv_75k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0119_juv_end.csv")
no_width_data <- read_csv('data_minimized/L2/0119_juv_no-widths.csv')
segment_vols <-  bind_rows(no_width_data, bmesh_run_1, bmesh_run_2)
segment_vols$iteration <- segment_vols$iteration+1
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
#width_presence <- read.csv('data/L0/width_presence_n_widths.csv')
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
cse_by_nwidths$rep_class <- 'Juvenile'
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
juv_cse <- cse_by_nwidths
both_rep_cse <- rbind(adult_cse, juv_cse)
library(stringr)
both_rep_cse$rep_class <- str_to_title(both_rep_cse$rep_class)
# below df is for experimenting with aesthetic options
#small_both_rep_cse <- sample_n(both_rep_cse, 13000)
tiff("figs/fig_4.tiff", units="in", width=6.5, height=4.31, res=300)
ggplot(filter(both_rep_cse, n_widths > 0), aes(as.factor(n_widths), y=prop_error*100, color=as.factor(n_widths))) +
geom_jitter(size=0.1) +
theme_bw() +
geom_hline(yintercept = 5, linetype='dashed') +
coord_cartesian(ylim=c(0,15)) +
scale_x_discrete('Number of Widths Included in Model') +
scale_y_continuous(expression(paste('Volume Error (% Total Volume)'))) +
facet_wrap(~rep_class) +
theme(legend.position = 'none',
axis.title.x = element_text(size=16, margin=margin(t=8)),
axis.title.y = element_text(size=16, margin=margin(r=10)),
axis.text.y = element_text(size = 10),
axis.text.x = element_text(size = 8),
strip.text = element_text(size=12, margin = margin(t=0.1, b=0.1))) + scale_color_viridis_d(option="C", direction = 1)
dev.off()
library(tidyverse)
###### for adult_best_width_combos ###
bmesh_run_1 <- read_csv("data_minimized/L2/0308_adult_0to30k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0308_adult_30to60k.csv")
bmesh_run_3 <- read_csv("data_minimized/L2/0308_adult_60to90k.csv")
bmesh_run_4 <- read_csv("data_minimized/L2/0308_adult_90ktoend.csv")
segment_vols= rbind(bmesh_run_1, bmesh_run_2, bmesh_run_3, bmesh_run_4)
segment_vols$iteration=1:nrow(segment_vols)
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
# make indices of model combinations
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
# convert to proportional error
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
cse_by_nwidths$rep_class <- 'adult'
adult_cse <- cse_by_nwidths
# extract ALL the models with < 5% error with 2-5 widths
adult_min_models <- filter(adult_cse, n_widths %in% c(2,3,4,5) & prop_error < 0.05)
#nrow(filter(juv_cse, prop_error < 0.05))
adult_best_width_combos <- filter(width_presence, iteration %in% adult_min_models$iteration) # gives the combinations only, no data
##########
# these are just the width measurement combinations
adult_best_model_widths <- read.csv('data_minimized/L3/0309_adult_minmodels.csv')
all_adults_full_models <- read_csv("data_minimized/L2/20220510_full-models.csv") %>% filter(rep_class =='adult')
#all_adults_full_models$Animal_ID <- unique(adult_best_model_widths$Animal_ID)
all_adults_full_models$model <- as.factor('full')
# these are the actual volume estimates from the scaled models
all_adults_best_models_1 <- read_csv("data_minimized/L4/0309_best_mods_adult_1.csv")
all_adults_best_models_2 <- read_csv("data_minimized/L4/0309_best_mods_adult_2.csv")
all_adults_best_models <- rbind(all_adults_best_models_1, all_adults_best_models_2)
all_adults_best_models$Animal_ID <- adult_best_model_widths$Animal_ID
all_adults_best_models$model <- rep(adult_best_width_combos$iteration, 15)
adult_all_models <- rbind(all_adults_best_models, select(all_adults_full_models, -c('TL', 'Image', 'rep_class')))
adult_all_models_long <- pivot_longer(adult_all_models, cols = `0`:`17`, names_to = 'segment')
adult_full_models <- filter(adult_all_models_long, model=='full')
adult_seg_vol_error <- adult_all_models_long %>% group_by(Animal_ID, model) %>%   # 4539 models for each animal
mutate(error=value-adult_full_models$value[which(adult_full_models$Animal_ID==Animal_ID)]) %>%
mutate(prop_seg_error=error/adult_full_models$value[which(adult_full_models$Animal_ID==Animal_ID)])
adult_cum_seg_error <- adult_seg_vol_error %>%
group_by(Animal_ID, model) %>%
summarise(cs_error=sum(abs(error))) # we want abs error
adult_full_models_tot_vol <- adult_full_models %>% group_by(Animal_ID) %>% summarise(perfect_vol=sum(value))
adult_cum_seg_error$perfect_vol <- rep(adult_full_models_tot_vol$perfect_vol, each=nrow(adult_best_width_combos)+1)
adult_cum_seg_error <- adult_cum_seg_error %>% mutate(prop_error=cs_error/perfect_vol)
#ggplot(cum_seg_error, aes(model, prop_error)) + geom_boxplot()
# this is too restrictive; aim for 95% instead
# adult_accepted_models <- adult_cum_seg_error %>% group_by(model) %>% filter(., max(prop_error) < 0.05 & model !='full')
# this is better
adult_accepted_models2 <- adult_cum_seg_error %>% group_by(model) %>% filter(., quantile(prop_error, 0.95) < 0.05 & model !='full')
adult_accepted_models2$dataset <- 'ours'
adult_accepted_models2$rep_class <- 'Adult'
adult_accepted_combos <- filter(width_presence, iteration %in% adult_accepted_models2$model)
############# make table for adults #######
accepted_smry <- adult_accepted_models2 %>% group_by(model) %>% summarise(avg_prop_error=mean(prop_error))
# identifying the models that were accepted
width_presence <- width_presence %>% rename(model = iteration)
width_presence$model <- as.character(width_presence$model)
models_under_5 <- inner_join(width_presence, accepted_smry, by = 'model')
adult_modunder5 <- models_under_5
foo <- adult_modunder5[,1:17] %>% summarise(n=colSums(.))
foo$width <- seq(5,85,5)
ggplot(foo, aes(as.factor(width), n)) + geom_bar(stat = 'identity')
models_under_5_sort <- models_under_5 %>%  arrange(across(Var1:Var17, desc))
for (i in 1:17) {
colnames(models_under_5_sort)[i] <- i*5
}
# function to make lists of necessary widths
foo <- apply(models_under_5_sort[,1:17], 1, function(x) names(which(x > 0)))
df1 <- data.frame(model=models_under_5_sort$model, col1=rep(NA,nrow(models_under_5_sort)), col2=round(models_under_5_sort$avg_prop_error,3))
for (i in 1:nrow(models_under_5_sort)) {
df1$col1[i] <- paste0(foo[,i], collapse = ', ')
}
library(flextable)
ft2 <- flextable(data=df1) %>% set_header_labels(model='Model', col1='Widths in Model', col2='Mean Proportional Error')
ft2 <- width(ft2, width=1.5) %>% align(., j=1, align = 'justify', part = 'body') # bottom line is present but not always visible in viewport
set_caption(ft2, 'Five-width models which resulted in < 5% error for 95% of adults')
##### JUVENILE STUFF ##############
bmesh_run_1 <- read_csv("data_minimized/L2/0119_juv_75k.csv")
bmesh_run_2 <- read_csv("data_minimized/L2/0119_juv_end.csv")
no_width_data <- read_csv('data_minimized/L2/0119_juv_no-widths.csv')
segment_vols <-  bind_rows(no_width_data, bmesh_run_1, bmesh_run_2)
segment_vols$iteration <- segment_vols$iteration+1
seg_vols_longer <- pivot_longer(segment_vols, cols = `0`:`17`, names_to = 'segment')
seg_vols_longer$segment <- as.numeric(seg_vols_longer$segment)+1
full_model <- filter(seg_vols_longer, iteration==max(iteration))$value
seg_vol_error <- seg_vols_longer %>%
mutate(error=value-full_model)
cum_seg_error <- seg_vol_error %>%
group_by(iteration) %>%
summarise(cs_error=sum(abs(error))) # we want absolute error
# calculate number of widths in each iteration
n <- 17
l <- rep(list(0:1), n)
test_df <- expand.grid(l)
test_df$iteration <- 1:nrow(test_df)
width_presence <- test_df %>% mutate(n_widths = rowSums(across(Var1:Var17)))
cse_by_nwidths <- left_join(width_presence, cum_seg_error, by='iteration')
# convert to proportional error
cse_by_nwidths <- cse_by_nwidths %>% mutate(prop_error=cs_error/sum(full_model))
# extract ALL the models with < 5% error with 5-6 widths
juv_min_models <- filter(cse_by_nwidths, n_widths %in% c(5,6) & prop_error < 0.05)
nrow(filter(juv_min_models))
juv_best_width_combos <- filter(width_presence, iteration %in% juv_min_models$iteration)
##### make the subset dataframe to feed into blender
`%ni%` <- Negate(`%in%`)
width_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
juv_morphs <- filter(width_data, rep_class=='juvenile') %>% select(-Image)
best_models <- data.frame()
# this loop takes a while to run
# code below saves the output as a .csv which is loaded below
# commented out to save time when reprocessing the data
# for (i in 1:nrow(juv_morphs)) { # for each whale
#
#   df1 <- data.frame()
#
#   for (k in 1:nrow(juv_best_width_combos)) {
#
#     v1 <- c()
#
#     for (j in 1:17) { # for each width for one whale
#
#       v1[j] <- ifelse(juv_best_width_combos[k,j], juv_morphs[i,j+3], NA)
#
#
#     }
#
#     df1[k,1:3] <- juv_morphs[i,c(1,2,3)]
#
#     df1[k,4:20] <- v1
#
#   }
#
#
#   best_models <- rbind(best_models, df1)
#
# }
# this writes the data out to get fed into blender
#write.csv(best_models, file = 'data_minimized/L3/0120_candidate-adult-models_juv-data.csv', row.names = F)
####### next step #######
candidate_models <- read_csv('data_minimized/L4/0121_all-juvie-candidate-models.csv')
juvie_data_w_repeats <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(rep_class=='juvenile')
#all_juvie_data <- read_csv('data/L1/0120_all-juvie-data.csv')
candidate_models$Animal_ID <- rep(juvie_data_w_repeats$Animal_ID, each=nrow(juv_best_width_combos))
candidate_models <- candidate_models %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
# these are actual volume estimates from FULL models
# NOTE: since this analysis was performed, the final models were updated such
# that the FULL model volumes are slightly different. The candidate models
# here are being compared to the full models generated at that point in time
# so that it is an "apples to apples" comparison.
full_model_data <- read_csv('data_minimized/L2/juv-full-models_old-version.csv') %>% mutate(
Animal_ID = juvie_data_w_repeats$Animal_ID
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1'))
colnames(full_model_data)[1:18] <- 1:18
full_model_data <- pivot_longer(full_model_data, cols = `1`:`18`, names_to = 'segment')
# calculate total body volume
full_model_data <- full_model_data %>% group_by(Animal_ID) %>% mutate(body_volume = sum(value)) %>% mutate(
segment = as.numeric(segment)
) %>% rename(
true_segment_volume = 'value',
true_body_volume = 'body_volume'
)
model_and_nwidths_df <- juv_best_width_combos %>% slice(rep(row_number(), 41)) %>% # number of measurements
mutate(Animal_ID = rep(juv_morphs$Animal_ID, each=nrow(juv_best_width_combos))) %>% rename(
model = 'iteration')# add the IDs of the models
# just group by iteration and number of widths
candidate_models <- bind_cols(candidate_models, select(model_and_nwidths_df, c(model, n_widths)))
colnames(candidate_models)[1:18] <- 1:18
candidate_models <- pivot_longer(candidate_models, cols = `1`:`18`, names_to = 'segment') %>% mutate(segment=as.numeric(segment)) %>% rename(
candidate_segment_vol = 'value'
)
candidate_models <-  left_join(candidate_models, full_model_data, by = c('Animal_ID', 'segment'))
candidate_models <- candidate_models %>% group_by(Animal_ID, model) %>%
mutate(segment_error = candidate_segment_vol - true_segment_volume,
prop_seg_error = abs(segment_error/true_body_volume)) # prop is absolute
# add up error
juv_cum_seg_error <- candidate_models %>%
group_by(Animal_ID, model) %>%
summarise(total_prop_error=sum(prop_seg_error))
juv_accepted_models <- juv_cum_seg_error %>% group_by(model) %>% filter(quantile(total_prop_error, 0.95) < 0.05)
juv_accepted_models$rep_class <- 'juvenile'
### finally making table?
accepted_smry <- juv_accepted_models %>% group_by(model) %>% summarise(avg_prop_error=mean(total_prop_error)) %>% mutate(model = as.character(model))
# identifying the models that were accepted
width_presence <- width_presence %>% rename(model = iteration)
width_presence$model <- as.character(width_presence$model)
models_under_5 <- inner_join(width_presence, accepted_smry, by = 'model')
juv_modunder5 <- models_under_5
foo <- juv_modunder5[,1:17] %>% summarise(n=colSums(.))
foo$width <- seq(5,85,5)
ggplot(foo, aes(as.factor(width), n)) + geom_bar(stat = 'identity')
models_under_5_sort <- models_under_5 %>%  arrange(across(Var1:Var17, desc))
for (i in 1:17) {
colnames(models_under_5_sort)[i] <- i*5
}
bwc_2 <- juv_best_width_combos
colnames(bwc_2)[1:17] <- seq(5, 85, 5)
which_widths <- filter(bwc_2, iteration %in% unique(juv_accepted_models$model)) %>% arrange(across(`5`:`85`, desc))
### make table prep
foo <- apply(which_widths[,1:17], 1, function(x) names(which(x > 0)))
df1 <- data.frame(model=which_widths$iteration, col1=rep(NA,nrow(which_widths)), col2=round(models_under_5_sort$avg_prop_error,3))
for (i in 1:nrow(which_widths)) {
df1$col1[i] <- paste0(foo[,i], collapse = ', ')
}
library(flextable)
ft3 <- flextable(data=df1) %>% set_header_labels(model='Model', col1='Widths in Model', col2= 'Mean Proportional Error')
ft3 <- width(ft3, width=2) %>% align(., j=1, align = 'justify', part = 'body') # bottom line is present but not always visible in viewport
ft3
ft2_mod <- delete_part(ft2, 'header') %>% add_header_row(., values='Adult', colwidths = 3) %>%
add_header_row(., values=c('Model', 'Widths in Model', 'Mean Proportional \n Error')) %>%
theme_booktabs(.) %>%
align(., align = 'center', part = 'header')
autofit(ft2_mod)
ft3_mod <- delete_part(ft3, 'header') %>% add_header_row(., values='Juvenile', colwidths = 3) %>%
theme_booktabs(.) %>%
align(., align = 'center', part = 'header')
autofit(ft3_mod)
save_as_docx(autofit(ft2_mod), path = 'figs/0202_adult-table_1.docx')
save_as_docx(autofit(ft3_mod), path = 'figs/0202_juv-table_1.docx')
########### this file generates figure 3 ###################
library(tidyverse)
`%ni%` <- Negate(`%in%`)
full_model_data <- read_csv('data_minimized/L2/20220510_full-models.csv') %>% mutate(
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
## transform data ##
full_model_data <- pivot_longer(full_model_data, cols = `0`:`17`, names_to = 'segment', values_to = 'segment_volume') %>%
mutate(segment=as.numeric(segment)+1)
full_model_data <- full_model_data %>% group_by(Animal_ID) %>% mutate(total_vol = sum(segment_volume)) %>% mutate(
prop_seg_vol = segment_volume/total_vol
)
full_model_data %>% group_by(rep_class) %>% summarise(mean(total_vol), sd(total_vol))
# make sure it sums to one
#sum(full_model_data$prop_seg_vol[1:18])
full_model_data <- full_model_data %>% rename('Repr. class' = rep_class)
library(rstatix)
full_model_data <- full_model_data %>% ungroup()
full_model_data$segment_fac <- as.factor(full_model_data$segment)
full_model_data$Animal_ID <- as.factor(full_model_data$Animal_ID)
full_model_data <- full_model_data %>% rename(rep_class = `Repr. class`)
# save the picture
tiff("figs/fig-3.tiff", units="in", width=6.5, height=4.31, res=300)
ggplot(full_model_data, aes(x=as.factor(segment), y=prop_seg_vol, color=rep_class)) + geom_boxplot() +
theme_bw() +
theme(legend.position = c(0.85, 0.85),
legend.background = element_rect(color='black')) +
ylab('Segment Volume (% Total Volume)') +
xlab('Body Segment') +
scale_color_viridis_d(option='B', begin=0.3, end=0.8)
dev.off()
########## this file generates table S1 ######################
library(tidyverse)
Dorso_lateral_data <- read_table("data_minimized/L0/Dorso.lateral.data.2017.2020.2021.txt")
colnames(Dorso_lateral_data) <- c('ID', 'rep_class', 'location', paste('w', as.character(seq(0.05, 0.95, 0.05)), sep = ''), paste('h', as.character(seq(0.05, 0.95, 0.05)), sep = ''), 'drslname', 'latname')
# assumed all individuals were 12 m long
# remove quotation marks
# remove outlier
data_in_analysis <- Dorso_lateral_data %>% mutate(across(w0.05:h0.95, .fns = ~ .x*12)) %>%
mutate(rep_class = gsub('"', '', rep_class),
ID = gsub('"', '', ID),
location = gsub('"', '', location)) %>%
filter(rep_class %in% c('Adult', 'Juvenile') & ID != '2017.06.15.60.01b') %>%
mutate(TL=12)
# get dates
data_in_analysis <- data_in_analysis %>% mutate(
date = anytime::anydate(substr(ID, 1, 10)),
month = lubridate::month(date),
year = lubridate::year(date),
dataset = 'Australia'
)
# how do we want to present this data?
# one row for each individual with dates and location?
table_df <- data_in_analysis %>% select(c('ID', 'dataset', 'location', 'rep_class', 'date')) %>% rename(Animal_ID = "ID")
library(flextable)
# ft1 <- flextable(data=table_df) %>% set_header_labels(dataset = 'Dataset', location = 'Location', rep_class = 'Repr. Class', Animal_ID = 'Animal ID', date = 'Date') %>%
#   #theme_booktabs() %>%
#   align(j=1, align = 'left', part = 'body') %>%
#   align(j=2, align = 'left', part = 'body') %>%
#   align(j=3, align = 'center', part = 'body') %>%
#   align(j=4, align = 'center', part = 'body')
#
# autofit(ft1)
# read in NY data
NY_data <- read_csv('data_minimized/L0/0215_morphs_58-whales.csv')
`%ni%` <- Negate(`%in%`)
# extract dates from Image column based on formattting
NY_data <- NY_data %>% mutate(
date = case_when(startsWith(Image, 'file') ~ substr(Image, 39, 46),
startsWith(Image, 'UAV_L0') ~ substr(Image, 13, 20),
startsWith(Image, 'final_formeas_file____Volumes') ~ substr(Image, 65, 72),
startsWith(Image, 'final_formeas_file____Users_EIH_Desktop') ~ '2021-10-07',
startsWith(Image, 'final_formeas_file____Users_EIH_Documents') ~ '2021-10-15')) %>%
mutate(
date = anytime::anydate(date),
dataset = 'New York',
location = '--',
Animal_ID = ifelse(Animal_ID==lag(Animal_ID, default = 'nada'), paste0(Animal_ID, '_1'), Animal_ID),
Animal_ID = ifelse(Animal_ID=='TLSCAR', 'TL0085', Animal_ID),
rep_class = stringr::str_to_title(rep_class)
) %>% filter(Animal_ID %ni% c('TL0092_1', 'TL0093_1')) # remove the 2 repeats
NY_table_df <-  NY_data %>% select(c('Animal_ID', 'dataset', 'location', 'rep_class', 'date'))
table_df <- bind_rows(table_df, NY_table_df)
ft1 <- flextable(data=table_df) %>% set_header_labels(dataset = 'Dataset', location = 'Location', rep_class = 'Repr. Class', Animal_ID = 'Animal ID', date = 'Date') %>%
#theme_booktabs() %>%
align(j=1, align = 'left', part = 'body') %>%
align(j=2, align = 'center', part = 'body') %>%
align(j=3, align = 'center', part = 'body') %>%
align(j=4, align = 'center', part = 'body')
autofit(ft1)
save_as_docx(autofit(ft1), path = 'figs/table-S1.docx')
#### this file generates table S2 ######################
library(tidyverse)
Dorso_lateral_data <- read_table2("data_minimized/L0/Dorso.lateral.data.2017.2020.2021.txt")
colnames(Dorso_lateral_data) <- c('ID', 'rep_class', 'location', paste('w', as.character(seq(0.05, 0.95, 0.05)), sep = ''), paste('h', as.character(seq(0.05, 0.95, 0.05)), sep = ''), 'drslname', 'latname')
#Dorso_lateral_data <- Dorso_lateral_data[,1:40]
HW_ratios <- data.frame(Dorso_lateral_data[,23:41]/Dorso_lateral_data[,4:22])
colnames(HW_ratios) <- as.character(seq(0.05, 0.95, 0.05))
HW_ratios <- cbind(Dorso_lateral_data[, 1:3], HW_ratios)
# exclude outlier, remove quotation marks
HW_ratios <- HW_ratios %>% mutate(rep_class = gsub('"', '', rep_class),
ID = gsub('"', '', ID),
location = gsub('"', '', location)) %>%
filter(ID != '2017.06.15.60.01b')
long_df <- HW_ratios %>% pivot_longer('0.05':'0.95', names_to= 'hw_int', values_to='hw_ratios')
mean_df <- filter(long_df, rep_class %in% c('Adult', 'Juvenile')) %>% group_by(rep_class, hw_int) %>% summarise(avg_hw_ratio=mean(hw_ratios))
# plotting the HW ratios
ggplot(filter(long_df, rep_class %in% c('Adult', 'Juvenile')), aes(x=as.factor(hw_int), y=hw_ratios, color=rep_class)) +
geom_line(aes(group=ID)) +
geom_line(data=mean_df, aes(hw_int, avg_hw_ratio, group=rep_class), size=2) +
#geom_jitter(width=0.1) +
#geom_boxplot() +
theme_bw() +
theme(legend.position = c(0.9, 0.9))
### TL not available, only relative widths and heights
### lets just say all the whales are 12 m in  length. recalc widths and heights:
DLD_fake_meas <- Dorso_lateral_data %>% mutate(across(w0.05:h0.95, .fns = ~ .x*12)) %>% mutate(rep_class = gsub('"', '', rep_class),                                          ID = gsub('"', '', ID),                                                        location = gsub('"', '', location)) %>%
filter(rep_class %in% c('Adult', 'Juvenile'), ID != '2017.06.15.60.01b') %>%
select(-location) %>%
mutate(TL=12)
# use these data to scale the base model
# use the mean HW data from these values to scale the base model
# ID, rep_class, TL, widths, heights
DLD_fake_meas <- DLD_fake_meas[,c(1,2,41, 3:21, 22:40)]
blender_ready_hw <- long_df %>% filter(rep_class %in% c('Adult', 'Juvenile') & hw_int < 0.9) %>% group_by(rep_class, hw_int) %>% summarise(avg_hw_ratio=round(mean(hw_ratios),3)) %>% pivot_wider(names_from = hw_int, values_from = avg_hw_ratio)
better_table <- long_df %>% filter(rep_class %in% c('Adult', 'Juvenile') & hw_int < 0.9) %>% group_by(rep_class, hw_int) %>% summarise(avg_hw_ratio=round(mean(hw_ratios),3)) %>% mutate(hw_int=as.numeric(hw_int)*100)
better_table <- cbind(better_table[1:17,2:3], better_table[18:34,3])
colnames(better_table)[2:3] <- c('mean_adult_hw_ratios', 'mean_juv_hw_ratios')
library(flextable)
ft3 <- flextable(data=better_table) %>% set_header_labels(hw_int = "Percent Total Length", mean_adult_hw_ratios = "Mean Adult HW ratios", mean_juv_hw_ratios = "Mean Juv. HW ratios") %>%
theme_booktabs() %>%
align(j=1, align = 'center', part = 'body') %>%
align(j=2, align = 'center', part = 'body') %>%
align(j=3, align = 'center', part = 'body')
autofit(ft3)
# generate table S2
save_as_docx(autofit(ft3), path = 'figs/table-S2.docx')
